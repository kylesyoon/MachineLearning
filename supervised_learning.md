# Decision Trees
## ID3
Split with best attribute again and again until classified.

What is "best"?
Maximize information gain.
Entropy = Randomness
Lower entropy!

## Inductive Bias
Restriction Bias = Hypothesis (All decision trees)
Preference Bias = What sort of hypothesis do we prefer out of the hypothesis set (a particular decision tree out of all of them)

#### ID3
Good splits near the top
Correct over incorrect
Shorter over longer

## Other Considerations
How to have continuous attributes?
Use ranges
